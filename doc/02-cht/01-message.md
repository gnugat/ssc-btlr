# cht:message

Using the `--help` option, the command will print the recommended way to run it:

```
./btlr cht:message --help
```

Copy paste the last line, and you're ready to go!

## Options

While it is recommened to use the example values given in the `--help` display,
it is possible to customize the different options.

### Manual Mode

When `--manual-mode true` is used, API calls to LLMs are disabled,
and the user is asked to:

* first copy paste the displayed prompts to their favorite LLMs (eg ChatGPT)
* then copy paste the LLM's completion back in the terminal

When given any other value (eg `--manual-mode false`, `--manual-mode 0`, etc),
then API calls to the configured, supported LLM are made.

> **Warning**: Currently no LLM API calls have been implemented,
> so only the Manual Mode will work.

### Config: LLM engine

When `--config-llm-engine "chatgpt-gpt-3.5-turbo"` is used,
[OpenAI's ChatGPT 3.5](https://chat.openai.com/) is set as the LLM engine to use.

> **Warning**: Currently no LLM API calls have been implemented,
> so this value is only used informatively in the logs to help determine how
> messages were generated.

### Config: Logs Filename

To enable Infinite Memory, and to be able to determine how each messages were
generated, the following need to be persisted somewhere as log entries:

* user prompt: what the user provided
* model completion: what the LLM generated

Another mechanism present to enable Infinite Memory is the consolidation of
memories by summarising the user messages and their model completions, which
are then persisted in:

* summaries: compressed information extracted from chunks of conversation

Finally, for debug purposes the prompt sent to the LLM are also logged:

* augmented prompt: the user prompt augmented with infinit memroy
* summary prompt: the prompt used to summarise chunks of conversations

When `--config-logs-filename ./var/cht/logs` is used,
they are persisted locally on the filesystem at the given path.

The following filename template is used to save the log entries:

* `%logs_filename%/%directory%/%time%_%priority%_%id%_%type%.json`

The placeholders will then be replaced with the appropriate values:

* `logs_filename`: with the value from the option
  (eg `./var/cht/logs`)
* `%time%`: a time generated by the system
* `%id%`: a UUID generated by the system
* `%type%`, and its associated `%priority%` and `%directory%`: one of
  * `user_prompt`, its priority is `000`, its directory `last_messages`
  * `model_completion`, its priority is `900`, its directory `last_messages`
  * `augmented_prompt`, its priority is `500`, its directory `prompts`
  * `summary_prompt`, its priority is `300`, its directory `prompts`
  * `summary`, its priority is `500`, its directory `summaries`

The log entries are stored in chronological order to make it easier to read
(the priority bit is used to make sure that log entries are listed in logical
order, for example that the user prompt always appear before the model
completion).

By setting a new path for the `--config-logs-filename` option, it is possible
to start a brand new conversation, and create memories that will not be shared
with the ones in `./var/cht/logs`.

### Config: Prompt Templates

Here are the different Prompt Templates used:

* augmented prompt: the user prompt augmented with infinit memery
* summary prompt: the prompt used to summarise chunks of conversations

When `--config-logs-filename ./templates/cht/prompts` is set,
the default templates will be used.

By copying the content of `./templates/cht/prompts`, modifying them,
and then setting the new path for that option, it is possible to customise
BTLR.

### Config: Chunk Memory Size

The value of `--config-chunk-memory-size` needs to be a multiple of 2,
as for each user prompt there are currently 2 log files in messages:
one for the user prompt and one for the model completion.

There is a Memory Pointer that will initially point to the first ever log.

If `--chunk-memory-size 10` is used, whenever the number of logs after the
memory pointer exceeds the configured Chunk Memory Size, a summary of the 
10 logs is generated, and the Memory Pointer gets moved to the 11th message.

The Last Messages section in the augmented prompt only includes logs from
the Memory Pointer on.

The Memory Extract section in the augmented prompt includes all the generated
log summaries.

### Config: Last Messages Size

When `--config-last-messages-size -1` is used, all the log messages from
`--config-logs-filename` that are more recent than the Memory Pointer will be
featured in the Last Messages section of the augmented prompt.

However as the conversation goes, the number of messages grow larger and
larger and if `--config-chunk-memory-size` is set to a high number, it could
lead to an augmented prompt that exceeds in size the LLM's token limit, and
therefore having it be truncated.

If changing the value of `--config-chunk-memory-size` to a lower setting is not
desired, then it's possible to change `--config-last-messages-size` to a
positive number: for example to 6 so that only the last 6 messages are included
will be included in the Last Messages section.

When `--config-last-messages-size 0` is used, then no messages are included in
the Last Messages section of the augmented prompt.

If the given number is `-2` or less, or greater than the number of messages
after the Memory Pointer, then it is ignored in favour of `-1` (which is all
messages after the Memory Pointer).

## Further documentation

You can find more information in the
`./doc/02-cht/01-message/01-prompt-templates.md` file.
