# cht:augment

Using the `--help` option, the command will print the recommended way to run it:

```
./btlr cht:augment --help
```

Copy paste the last line, and you're ready to go!

## Options

While it is recommened to use the example values given in the `--help` display,
it is possible to customize the different options.

### Manual Mode

When `--manual-mode true` is used, API calls to LLMs are disabled,
and the user is asked to:

* first copy paste the displayed prompts to their favorite LLMs (eg ChatGPT)
* then copy paste the LLM's completion back in the terminal

When given any other value (eg `--manual-mode false`, `--manual-mode 0`, etc),
then API calls to the configured, supported LLM are made.

> **Warning**: Currently no LLM API calls have been implemented,
> so only the Manual Mode will work.

### Config: LLM engine

When `--config-llm-engine "chatgpt-gpt-3.5-turbo"` is used,
[OpenAI's ChatGPT 3.5](https://chat.openai.com/) is set as the LLM engine to use.

> **Warning**: Currently no LLM API calls have been implemented,
> so this value is only used informatively in the logs to help determine how
> messages were generated.

### Config: Logs

To enable Infinite Memory, and to be able to determine how each messages were
generated, the following need to be persisted somewhere as log entries:

* user prompt: what the user provided
* augmented prompt: the final prompt to be given to the LLM
* model completion: what the LLM generated

When `--config-logs-filename ./var/cht/logs` is used, they persisted locally
on the filesystem, at the given path.

The following options can then be used to specify where exactly each log entry
will be saved:

* `--config-user-prompt-log-filename-template "%logs_filename%/conversation/%time%_000_%id%_%source%.json`
* `--config-augmented-prompt-log-filename-template "%logs_filename%/augmentations/%time%_%id%.json`
* `--config-model-completion-log-filename-template "%logs_filename%/conversation/%time%_900_%id%_%source%.json`

Those filenames can use the following placeholders:

* `%id%`: a UUID generated by the system
* `%logs_filename%`: the value of `--config-logs-filename`
* `%time%`: a time generated by the system
* `%source%`: whether the log entry is for user prompt, augmented prompt, model completion, etc

The values suggested by the `--help` option allow the user prompt and model
completion log entries to be stored in the same conversation directory,
in chronological order.

The `000` and `900` bit will ensure that if they both happen at the same time,
the user prompt will still appear before the model completion.

### Config: Prompt Templates

The user prompt is augmented by using prompt templates.

Custom ones can be used with the following options:

* `--config-augmented-prompt-template-filename`

You can find more information in the
`./doc/02-cht/01-augment/01-prompt-templates.md` file.
